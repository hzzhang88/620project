---
title: "Central Code"
author: '620'
date: "2/28/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
t1 = read_excel(path = './rawdata/t1.xlsx',
                col_types = c("date","numeric","numeric","numeric","date",'text','logical'))
t2 = read_excel(path = './rawdata/t2.xlsx',
                  col_types = c("date","numeric","numeric","numeric","date",'text','logical'))
t3 = read_excel(path = './rawdata/t3.xlsx',
                col_types = c("date","numeric","numeric","numeric","date",'text','logical'))
for (i in 1:length(t3$date)) {
  t3$pickups_1st[i] = ymd_hms(paste(as.character(t3$date[i]), strsplit(as.character(t3$pickups_1st[i]),split = " ")[[1]][2]))
}

colnames(t2) = c('date',"total_st","social_st","pickups","pickups_1st","weekday","if_weekend")
colnames(t3) = c('date',"total_st","social_st","pickups","pickups_1st","weekday","if_weekend")
for (i in 1:length(t2$date)) {
  t2$pickups_1st[i] = ymd_hms(paste(as.character(t2$date[i]), strsplit(as.character(t2$pickups_1st[i]),split = " ")[[1]][2]))
}

t1[['first_pick_time']] = hour(t1$pickups_1st) + minute(t1$pickups_1st)/60
t2[['first_pick_time']] = hour(t2$pickups_1st) + minute(t2$pickups_1st)/60
t3[['first_pick_time']] = hour(t3$pickups_1st) + minute(t3$pickups_1st)/60
t1 = cbind(t1,id = 1)
t2 = cbind(t2,id = 2)
t3 = cbind(t3,id = 3)
tt = rbind(t1,t2,t3)

```

<<<<<<< HEAD
#Federated learning
=======
# federated learning
>>>>>>> 4491f693ebd04533fb3534e6bdfb0d2c2794bf8a
use the received n1,n2,n3
```{r}
n = n1+n2+n3
x_bar = (n1*x_bar_1 + n2*x_bar_2+n3*x_bar_3)/n
x_bar = (n1*y_bar_1 + n2*y_bar_2+n3*y_bar_3)/n
```
use the received ssx1,ssx2,ssx3
use the SSXY 1-3
```{r}
ssx = ssx1+ssx2+ssx3
ssxy = ssxy1 +ssxy2+ ssxy3
beta1_hat = ssxy/ssx
beta0_hat = y_bar- beta1_hat*x_bar
```
use the received SSE1-3
```{r}
MSE_total = (SSE1+SSE2+SSE3)/(n-2)
var_beta1_hat = MSE_total/ssx
st_beta1_hat = sqrt(var_beta1_hat)
p_value_beta1 = pt(beta1_hat/st_beta1_hat,n-2,lower.tail = F)*2
var_beta0_hat = MSE_total*(1/n + x_bar^2/ssx)
st_beta0_hat = sqrt(var_beta0_hat)
p_value_beta0 = pt(beta0_hat/st_beta0_hat,n-2,lower.tail = F)*2
```

# meta learning 

receive the coefficients and variance
```{r}
t1_d = read.csv('./summarydata/t1_d.csv')
t2_d = read.csv('./summarydata/t2_d.csv')
t3_d = read.csv('./summarydata/t3_d.csv')
p = 4
for(i in c(1 : p)){  
  beta1 = t1_d$betas[i]
  beta2 = t2_d$betas[i]
  beta3 = t3_d$betas[i]
  varbeta1 = t1$vars[i]^2
  varbeta2 = t2$vars[i]^2
  varbeta3 = t3$vars[i]^2
  
  c1 = (1 / varbeta1) / (1 / varbeta1 + 1 / varbeta2 + 1 / varbeta3)
  c2 = (1 / varbeta2) / (1 / varbeta1 + 1 / varbeta2 + 1 / varbeta3)
  c3 = (1 / varbeta3) / (1 / varbeta1 + 1 / varbeta2 + 1 / varbeta3)
  
  beta_m = c1 * beta1 + c2 * beta2 + c3 * beta3
  varbetam =  c1^2 * varbeta1 + c2^2 * varbeta2 + c3^2 * varbeta3
  t = beta_m / sqrt(varbetam)
  print(paste('Meta beta', i - 1, ':', round(beta_m, 4)))
  print(paste('variance of Meta beta', i - 1, ':', round(varbetam, 4)))
}
```

# draw the tables

|name|first $\hat{\beta}$|first $var(\hat{\beta})$|second $\hat{\beta}$|second $var(\hat{\beta})$|third  $\hat{\beta}$|third $var(\hat{\beta})$|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|Intercept|-19.1822|727.8887|44.3858|10023.49|31.3864|7812.156|
|Pickups|0.5049|0.0166|0.8294|0.04489|0.3623|0.5368|
|first pickup time|5.0391|7.4230|-2.6160|232.43|15.8500|120.7953|
|if weekend|2.9078|62.5621|5.4941|248.3358|-18.1172|838.5326
<p style="text-align: center;">Table 1</p>

|meta$\hat{\beta_0}$|meta$\hat{\beta_1}$|meta$\hat{\beta_2}$|meta$\hat{\beta_3}$|
|:---:|:---:|:---:|:---:|
| -11.1823 | 0.5875 | 5.4231 | 2.2165 |
<p style="text-align: center;">Table 2</p>


# comfirmation analysis

```{r}
comfirm1 = lm(as.formula(paste(y,'~', x)),data=tt)
summary(comfirm1)
```

```{r}
mul_fit= lm(social_st ~ pickups+if_weekend+first_pick_time,data = t3)
summary(mul_fit)
```

